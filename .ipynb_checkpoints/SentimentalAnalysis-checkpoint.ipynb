{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974ff619",
   "metadata": {},
   "source": [
    "# Malignant Comment Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d2e05",
   "metadata": {},
   "source": [
    "Social media has been trending for the past decades. New forms of media, such as Instagram, Reddit, Discord, online forums, and chat applications, have become widely used as means of communication. However, there have been many cases of cyberbullying, hate speeches, trolls, and inappropriate languages used within these applications that have to be moderated. In this notebook, we will go through the steps of building an ML model using Naives Bayes Classifier to identify texts that are innaproppriate.\n",
    "\n",
    "We will be doing two models:\n",
    "1. Naives Bayes from scratch\n",
    "2. Naives Bayes with sklearn.naives_bayes\n",
    "\n",
    "The dataset used is from kaggle: https://www.kaggle.com/datasets/surekharamireddy/malignant-comment-classification\n",
    "\n",
    "Github link to this notepad:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4204af0",
   "metadata": {},
   "source": [
    "***\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aae694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp,log\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea5185",
   "metadata": {},
   "source": [
    "***\n",
    "### Exploratory Data Analysis ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659f9bfc",
   "metadata": {},
   "source": [
    "<b> Let's read the Data from the dataset <b>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa16ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDf = pd.read_csv('MalignantComment.csv')\n",
    "totalDf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e03089",
   "metadata": {},
   "source": [
    "**Note** There are six different classifications from which a comment can be ruled under. We can create a new column in this dataframe which encompasses every other classification. We will call the column 'negative' which will imply that the text was classified any of the six different classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cedcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new list that holds the values of the new column 'negative'\n",
    "list_negative = []\n",
    "\n",
    "#iterate through the dataframe and append '1' if the text was classified inappropriate, else append '0'\n",
    "for i,row in totalDf.iterrows():\n",
    "    if(row['malignant'] == 1 or row['highly_malignant'] == 1 or row['rude'] == 1 or row['threat'] == 1 or row['abuse'] == 1 or row['loathe'] == 1):\n",
    "        list_negative.append(1)\n",
    "    else:\n",
    "        list_negative.append(0)\n",
    "        \n",
    "#Insert the list into the dataframe\n",
    "totalDf.insert(loc=8,column =  \"negative\", value = list_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250d07d",
   "metadata": {},
   "source": [
    "**Note** Next, we need to preprocess the data in column 'comment_text'. As of now, each entry is one giant string that includes unwanted special characters. We will use regex to place characters outside of the english alphabet and numbers, replacing it with a empty space. We will then use the lowercase of all strings.\n",
    "\n",
    "* From scratch implementation will need a list of clean words.\n",
    "* Sklearn implementation will just need the cleaned text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee0f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for scratch implementation column\n",
    "list_comment_text = []\n",
    "#List for sklearn implementation column\n",
    "sk_comment_text = []\n",
    "\n",
    "#Iterate over the dataframe to replace, make lower case, and split/append accordingly\n",
    "for i,row in totalDf.iterrows():\n",
    "    long_text = re.sub('[^0-9a-zA-Z]+', ' ', row['comment_text']).lower()\n",
    "    list_comment_text.append(long_text.split())\n",
    "    sk_comment_text.append(long_text)\n",
    "\n",
    "#Create columns using the lists created\n",
    "totalDf.insert(loc=1,column =  \"list_comment_text\", value = list_comment_text)\n",
    "totalDf.insert(loc=1,column =  \"sk_comment_text\", value = sk_comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4626168",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d17ee1",
   "metadata": {},
   "source": [
    "Now our data is clean!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ea865",
   "metadata": {},
   "source": [
    "***\n",
    "## Naives Bayes Classifier from scratch ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bf8f1",
   "metadata": {},
   "source": [
    "The Naives Bayes Classifier is an ML technique derived from Bayes Theorem. Bayes Theorem States:\n",
    "\n",
    "**P(A | B) * P(B) = P(B | A) * P(A)**<br>\n",
    "or<br>\n",
    "**P(A | B) = P(B | A) * P(A) / P(B)**<br>\n",
    "\n",
    "We can use Bayes theorem to vision our problem case as:\n",
    "***\n",
    "#### *P(Inappropriate | Words in List) = P(Inappropriate) * P(Words in List | Inappropriate) / P(Words in List)*\n",
    "#### *P(Appropriate | Words in List) = P(Appropriate) * P(Words in List | Appropriate) / P(Words in List)*\n",
    "***\n",
    "&emsp;***P(Inappropriate | Words in List)*** is our predicted probability that given text is inappropriate\n",
    "\n",
    "&emsp;***P(Appropriate | Words in List)*** is our predicted probability that given text is appropriate\n",
    "\n",
    "&emsp;***P(Inappropriate)*** is the probability that a generalized text is inappropriate<br>\n",
    "&emsp;&emsp; = (# of texts label 1)/(# of total texts)\n",
    "\n",
    "&emsp;***P(Appropriate)*** is the probability that a generalized text is appropriate<br>\n",
    "&emsp;&emsp; = (# of texts label 0)/(# of total texts)\n",
    "\n",
    "&emsp;***P(Words in List)*** is the probability of a specific generalized text<br>\n",
    "&emsp;&emsp; This probability is very hard to compute, and will not be using this probability as we compare<br>\n",
    "&emsp;&emsp; P(Appropriate | Words in List) with P(Inappropriate | Words in List)\n",
    "\n",
    "&emsp;***P(Words in List | Inappropriate)*** is the probability that the words in the text are in an inappropriate labeled text<br>\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca7b545",
   "metadata": {},
   "source": [
    "Let's dive separately into ***P(Words in List | Inappropriate)***\n",
    "\n",
    "Since Naives Bayes assumes independence for each word in the text: Therefor <br>\n",
    "&emsp;&emsp;*P(Words in List | Inappropriate)* = <br>\n",
    "&emsp;&emsp;*P(Word1 and Word2 and Word3 ... WordN | Inappropriate)* = <br>\n",
    "&emsp;&emsp;*P(Word1| Inappropriate) * P(Word2| Inappropriate) * ... * P(WordN| Inappropriate)*<br>\n",
    "&emsp;&emsp;**Where**<br>\n",
    "&emsp;&emsp;*P(WordN| Inappropriate)* = (# of WordN appearances in Inappropriate text)/(# of total words in Inappropriate text)\n",
    "\n",
    "However, there may be cases where WordN doesn't appear in our training Inappropriate text\n",
    "To account for this, let us add 1 to all unique values in all text, giving us:<br>\n",
    "***P(WordN | Inappropriate)* = <br>\n",
    "((# of WordN appearances in Inappropriate text) + 1)/((# of total words in Inappropriate text) + (# of total unique words in all text)**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce4815",
   "metadata": {},
   "source": [
    "Let's go into the implementation so see how this is coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fa173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class naivesBayesSentiment:\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        #Calculate the number of rows in training set\n",
    "        self.n_rows = 0\n",
    "        \n",
    "        #Calculate P(Malignant), P(Highly Malignant), ...\n",
    "        self.prob_neg = 0\n",
    "        \n",
    "        #Calculate P(Word | Malignant) and P(Word | not Malignant)\n",
    "        self.neg_Dict = {}\n",
    "        self.pos_Dict = {}\n",
    "    \n",
    "    \n",
    "    def _prepopulateWordDict(self, wordList):\n",
    "        returnDict = {}\n",
    "        wordSet = set(wordList)\n",
    "        for word in wordSet:\n",
    "            returnDict[word] = 1\n",
    "        return returnDict\n",
    "    \n",
    "    def _calculate_Neg_Dict(self, x_train, y_train):\n",
    "        neg_list = []\n",
    "        pos_list = []\n",
    "        for x,y in zip(x_train, y_train):\n",
    "            if(y == 1):\n",
    "                neg_list.extend(x)\n",
    "            else:\n",
    "                pos_list.extend(x)\n",
    "\n",
    "        #prepopulate the dictionary with smoothing curve alpha\n",
    "        total_Word_List = neg_list + pos_list\n",
    "        neg_Dict = self._prepopulateWordDict(total_Word_List)\n",
    "        pos_Dict = self._prepopulateWordDict(total_Word_List)\n",
    "        \n",
    "        #create a dictionary of\n",
    "        #key -> word\n",
    "        #value -> word count + 1\n",
    "        for word in neg_list:\n",
    "            if (word in neg_Dict):\n",
    "                neg_Dict[word] += 1\n",
    "        \n",
    "        for word in pos_list:\n",
    "            if (word in pos_Dict):\n",
    "                pos_Dict[word] += 1\n",
    "                \n",
    "        #Sort the Dictionaries\n",
    "        neg_Dict= dict(sorted(neg_Dict.items(), key=lambda item: item[1], reverse = True)) \n",
    "        pos_Dict= dict(sorted(pos_Dict.items(), key=lambda item: item[1], reverse = True)) \n",
    "        return neg_Dict, pos_Dict\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.n_rows = len(x_train)\n",
    "        self.prob_neg = sum(y_train)/self.n_rows\n",
    "        self.neg_Dict, self.pos_Dict = self._calculate_Neg_Dict(x_train, y_train)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        #X will be a 2-d array\n",
    "        pred_y = []\n",
    "        prob_neg = 1\n",
    "        prob_pos = 1\n",
    "        sum_Neg = sum(self.neg_Dict.values())\n",
    "        sum_Pos = sum(self.pos_Dict.values())\n",
    "        for x_test in X:\n",
    "            prob_neg = self.prob_neg\n",
    "            prob_pos = 1 - self.prob_neg\n",
    "            for word in x_test:\n",
    "                if(word in self.neg_Dict):\n",
    "                    #formula for naivebayes\n",
    "                    prob_neg *= self.neg_Dict[word]/sum_Neg\n",
    "                    prob_pos *= self.pos_Dict[word]/sum_Pos\n",
    "            if(prob_neg > prob_pos):\n",
    "                pred_y.append(1)\n",
    "            else:\n",
    "                pred_y.append(0)\n",
    "        return pred_y\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b523e",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = totalDf['list_comment_text'].tolist()\n",
    "Y = totalDf['negative'].tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c058f77",
   "metadata": {},
   "source": [
    "**Create the model and fit the training data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ade33",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_Model = naivesBayesSentiment().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d15e47",
   "metadata": {},
   "source": [
    "**Calling the fit(X,y) function will generate two dictionaries**\n",
    "* Dictionary of unique word counts in Appropriate\n",
    "* Dictionary of unique word counts in Inappropriate\n",
    "\n",
    "**Note** These dictionaries have been adjusted so that all unique values in all texts have a initial value of 1.<br>\n",
    "e.g Dictionary['key'] == ((# of WordN appearances in Inappropriate text) + 1)<br>\n",
    "e.g sum of all values in Dictionary == ((# of total words in Inappropriate text) + (# of total unique words in all text)<br>\n",
    "\n",
    "Let's print out some of the dictionary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384cd2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(nbs_Model.neg_Dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe15d2",
   "metadata": {},
   "source": [
    "**Calling the predict(X) function will apply the Bayes Theorem formula**\n",
    "\n",
    "&emsp;&emsp;***P(Appropriate | Words in List) = P(Appropriate) * P(Words in List | Appropriate) / P(Words in List)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67939c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = nbs_Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565cbdbd",
   "metadata": {},
   "source": [
    "### Prediction Analysis for NBC ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3662099",
   "metadata": {},
   "source": [
    "Some helper functions to calculate precision and recall scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(y_true, y_pred, pos_label_value=1.0):\n",
    "\n",
    "    if(len(y_true) != len(y_pred)):\n",
    "        return -1\n",
    "    \n",
    "    TrueP = 0 \n",
    "    FalseP = 0\n",
    "    #We need to calculate total True positives and False postives\n",
    "    for yt, yp in zip(y_true,y_pred):\n",
    "        if(yt == pos_label_value and yp == pos_label_value):\n",
    "            #add to TrueP\n",
    "            TrueP += 1\n",
    "        if(yt != pos_label_value and yp == pos_label_value):\n",
    "            #add to FalseP\n",
    "            FalseP += 1\n",
    "    \n",
    "    precision = TrueP/(TrueP + FalseP)\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def calculate_recall(y_true, y_pred, pos_label_value=1.0):\n",
    "    \n",
    "    TrueP = 0 \n",
    "    FalseN = 0\n",
    "    #We need to calculate total True positives and False postives\n",
    "    for yt, yp in zip(y_true,y_pred):\n",
    "        if(yt == pos_label_value and yp == pos_label_value):\n",
    "            #add to TrueP\n",
    "            TrueP += 1\n",
    "        if(yt == pos_label_value and yp != pos_label_value):\n",
    "            #add to FalseP\n",
    "            FalseN += 1\n",
    "    \n",
    "    \n",
    "    recall = TrueP/(TrueP + FalseN)\n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504f116",
   "metadata": {},
   "source": [
    "Calculation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9461435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ac = accuracy_score(pred_y, y_test)\n",
    "print('Accuracy score: ' + str(ac))\n",
    "print('Precision score: ' + str(calculate_precision(y_test, pred_y)))\n",
    "print('Recall score: ' + str(calculate_recall(y_test, pred_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c0e79",
   "metadata": {},
   "source": [
    "This model has an relatively decent accuracy score. This score is high in comparison to the precision and recall scores since the score of true negatives are high.\n",
    "\n",
    "Ways to improve this model include:\n",
    "* Improving the lexigraph of what is stored in the dictionary. There are infinite amount of ways to mistype, abbreviate, and create new words. There may be a way to categorize these situations better.\n",
    "* Increasing training data\n",
    "\n",
    "Unfortunately, since this is a Naives Bayes, there will always be a limitation that each word in the testing text will be independent of each other. That is not the case, since the gramatical structure of the english language is somewhat dependent on the text phrase before hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676b2b3",
   "metadata": {},
   "source": [
    "## Bonus: Naives Bayes Classifier using sklearn ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54285ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sklearn = totalDf['sk_comment_text']\n",
    "Y_sklearn = totalDf['negative']\n",
    "\n",
    "X_train_sk, X_test_sk, y_train_sk, y_test_sk = train_test_split(X_sklearn, Y_sklearn, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2236dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorize', CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b\\w+\\b')),\n",
    "                       ('classifier', MultinomialNB())])\n",
    "pipe.fit(X_train_sk, y_train_sk)\n",
    "y_predict = pipe.predict(X_test_sk)\n",
    "\n",
    "print('Accuracy score: ' + str(accuracy_score(y_test_sk, y_predict)))\n",
    "print('Precision score: ' + str(calculate_precision(y_test_sk, y_predict)))\n",
    "print('Recall score: ' + str(calculate_recall(y_test_sk, y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a2bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
